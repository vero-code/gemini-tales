# ğŸ—ï¸ Architecture â€” Gemini Tales

> Deep-dive into the system design, component responsibilities, data flows, and key design decisions.

---

## Table of Contents

1. [High-level Overview](#1-high-level-overview)
2. [Repository Layout](#2-repository-layout)
3. [Subsystem A â€” Live Storytelling (Frontend)](#3-subsystem-a--live-storytelling-frontend)
   - [Component Map](#31-component-map)
   - [State Machine](#32-state-machine)
   - [Live API Session Lifecycle](#33-live-api-session-lifecycle)
   - [Tool-call Protocol](#34-tool-call-protocol)
   - [Audio Pipeline](#35-audio-pipeline)
   - [Camera Pipeline](#36-camera-pipeline)
4. [Subsystem B â€” Multi-agent Story Engine (Backend)](#4-subsystem-b--multi-agent-story-engine-backend)
   - [Agent Roles](#41-agent-roles)
   - [Orchestration Logic](#42-orchestration-logic)
   - [A2A Communication](#43-a2a-communication)
   - [FastAPI Proxy Layer](#44-fastapi-proxy-layer)
5. [Data Flows](#5-data-flows)
   - [Live Storytelling End-to-End](#51-live-storytelling-end-to-end)
   - [Multi-agent Story Engine End-to-End](#52-multi-agent-story-engine-end-to-end)
6. [Service Topology & Ports](#6-service-topology--ports)
7. [Deployment](#7-deployment)
8. [Key Design Decisions](#8-key-design-decisions)
9. [Tech Stack Summary](#9-tech-stack-summary)

---

## 1. High-level Overview

Gemini Tales consists of **two independent subsystems** that share a common Google AI backbone:

| Subsystem | Where it runs | Primary API |
|---|---|---|
| **Live Storytelling** | Browser (React/Vite) | Gemini Live API (WebSocket) |
| **Story Engine** | Server (Python/FastAPI) | Gemini via Google ADK + A2A |

The two subsystems are deployed together: the FastAPI server serves the compiled frontend as static files, and exposes a `/api/chat_stream` endpoint for the Story Engine UI.

Browser
  â”œâ”€â”€ Live Storytelling (WebSocket â†’ Gemini Live API)   [direct, no backend]
  â””â”€â”€ Story Engine UI (HTTP â†’ FastAPI â†’ ADK Agents)

Server (Cloud Run / localhost)
  â”œâ”€â”€ FastAPI app (port 8000)
  â”œâ”€â”€ Orchestrator (port 8004)
  â”œâ”€â”€ Adventure Seeker (Researcher - 8001)
  â”œâ”€â”€ Guardian of Balance (Judge - 8002)
  â””â”€â”€ Storysmith (Content Builder - 8003)


---

## 2. Repository Layout

```
gemini-tales/
â”œâ”€â”€ frontend/                       # React 19 + Vite 6 + TypeScript
â”‚   â”œâ”€â”€ index.html
â”‚   â”œâ”€â”€ vite.config.ts
â”‚   â”œâ”€â”€ package.json
â”‚   â””â”€â”€ src/
â”‚       â”œâ”€â”€ main.tsx                # React entry point
â”‚       â”œâ”€â”€ App.tsx                 # Entire Live storytelling app (single-component)
â”‚       â”œâ”€â”€ types.ts                # AppState enum, Achievement, StoryScene interfaces
â”‚       â””â”€â”€ services/
â”‚           â””â”€â”€ audioUtils.ts       # PCM encode / decode / AudioBuffer helpers
â”‚
â”œâ”€â”€ pyproject.toml              # Root workspace manifest (uv)
â”œâ”€â”€ run_local.ps1               # Starts all 5 services locally
â”œâ”€â”€ deploy.sh                   # Deploys all 5 services to Cloud Run
â”œâ”€â”€ shared/                     # Shared utilities (authenticated_httpx)
â”‚
â”œâ”€â”€ agents/
â”‚   â”œâ”€â”€ researcher/
â”‚   â”‚   â”œâ”€â”€ agent.py            # ADK Agent with google_search tool (gemini-2.5-pro)
â”‚   â”‚   â””â”€â”€ Dockerfile
â”‚   â”œâ”€â”€ judge/
â”‚   â”‚   â”œâ”€â”€ agent.py            # ADK Agent with structured JudgeFeedback output schema
â”‚   â”‚   â””â”€â”€ Dockerfile
â”‚   â”œâ”€â”€ content_builder/
â”‚   â”‚   â”œâ”€â”€ agent.py            # ADK Agent â€” writes the final course markdown
â”‚   â”‚   â””â”€â”€ Dockerfile
â”‚   â””â”€â”€ orchestrator/
â”‚       â”œâ”€â”€ agent.py            # SequentialAgent + LoopAgent + EscalationChecker
â”‚       â””â”€â”€ Dockerfile
â”‚
â””â”€â”€ app/
    â”œâ”€â”€ main.py                 # FastAPI server â€” proxy to orchestrator + static files
    â”œâ”€â”€ authenticated_httpx.py  # Google-auth aware httpx client factory
    â”œâ”€â”€ Dockerfile
    â””â”€â”€ frontend/               # Compiled Vite build (copied here before deploy)
```

---

## 3. Subsystem A â€” Live Storytelling (Frontend)

The entire interactive experience lives in a **single React component** (`App.tsx`). It connects directly to the Gemini API from the browser â€” there is no backend involved in the storytelling path.

### 3.1 Component Map

```
App.tsx
  â”œâ”€â”€ State: AppState { IDLE â†’ STARTING â†’ STORYTELLING }
  â”œâ”€â”€ Refs
  â”‚   â”œâ”€â”€ videoRef          â€” <video> element for camera preview
  â”‚   â”œâ”€â”€ canvasRef         â€” off-screen canvas for JPEG frame capture
  â”‚   â”œâ”€â”€ audioContextInRef â€” AudioContext @ 16 kHz  (microphone input)
  â”‚   â”œâ”€â”€ audioContextOutRefâ€” AudioContext @ 24 kHz  (AI audio output)
  â”‚   â”œâ”€â”€ sourcesRef        â€” Set<AudioBufferSourceNode> (for interruption)
  â”‚   â”œâ”€â”€ nextStartTimeRef  â€” scheduled playback cursor
  â”‚   â””â”€â”€ sessionPromiseRef â€” Promise<Session> (Live API handle)
  â”‚
  â”œâ”€â”€ generateNewIllustration(prompt)   â†’ Gemini Image API
  â”œâ”€â”€ handleAwardBadge(badgeId)         â†’ local state mutation
  â”œâ”€â”€ selectChoice(choice)              â†’ s.send({ text })
  â”œâ”€â”€ handleSessionMessage(message)     â†’ dispatches all server events
  â”œâ”€â”€ startStory()                      â†’ opens camera + Live session
  â””â”€â”€ stopStory()                       â†’ cleans up all resources
```

### 3.2 State Machine

```
IDLE
  â”‚  user clicks "Begin Your Story"
  â–¼
STARTING  â†â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚  camera permission granted               â”‚ camera error
  â”‚  Live API session connecting             â”‚
  â–¼                                          â”‚
STORYTELLING â”€â”€â”€â”€â”€â”€â”€â”€ onclose / stopStory() â”€â”˜
  â”‚  all interactions happen here
  â–¼
IDLE  (after stopStory)
```

### 3.3 Live API Session Lifecycle

```
startStory()
  1. getUserMedia({ video: true, audio: true })
  2. new AudioContext({ sampleRate: 16000 })   â† microphone
  3. new AudioContext({ sampleRate: 24000 })   â† speaker
  4. ai.live.connect(model, config, callbacks)
       â”œâ”€â”€ onopen  â†’ send initial "Start the magical fairy tale..." turn
       â”‚            connect ScriptProcessor for mic streaming
       â”‚            start setInterval (4 s) for camera frames
       â”œâ”€â”€ onmessage â†’ handleSessionMessage()
       â””â”€â”€ onclose â†’ AppState.IDLE

stopStory()
  1. clearInterval (frame capture)
  2. s.close()
  3. stop all MediaStream tracks
  4. reset state
```

### 3.4 Tool-call Protocol

The AI can call three **function tools** during the session. The frontend handles them inside `handleSessionMessage â†’ message.toolCall`:

| Tool | Args | Frontend action | Response sent back |
|---|---|---|---|
| `generateIllustration` | `prompt: string` | Calls `generateNewIllustration(prompt)` â†’ sets `currentIllustration` | `{ result: "Done" }` |
| `awardBadge` | `badgeId: string` | Calls `handleAwardBadge(badgeId)` â†’ unlocks achievement, shows popup | `{ result: "Awarded" }` |
| `showChoice` | `options: string[]` | Sets `storyChoices` â†’ renders overlay buttons | `{ result: "Options shown" }` |

All tool responses are sent via `s.sendToolResponse()`.

### 3.5 Audio Pipeline

```
Microphone (getUserMedia)
  â””â”€â–º MediaStreamSource
        â””â”€â–º ScriptProcessor (bufferSize: 4096, mono, 16 kHz)
              â””â”€â–º onaudioprocess
                    â””â”€â–º createPcmBlob(Float32Array)   [audioUtils.ts]
                          â””â”€â–º s.sendRealtimeInput({ media: blob })

Gemini Live API Response (24 kHz PCM)
  â””â”€â–º message.serverContent.modelTurn.parts[0].inlineData.data  (base64)
        â””â”€â–º decode(base64)                           [audioUtils.ts]
              â””â”€â–º decodeAudioData(pcm, ctx, 24000, 1) [audioUtils.ts]
                    â””â”€â–º AudioBufferSourceNode.start(nextStartTime)
                          â””â”€â–º ctx.destination (speakers)

Interruption:
  message.serverContent.interrupted = true
  â””â”€â–º sourcesRef.forEach(s => s.stop())
      nextStartTimeRef = 0
```

### 3.6 Camera Pipeline

```
setInterval(4000ms)
  â””â”€â–º canvas.drawImage(videoRef, 0, 0, 320, 240)
        â””â”€â–º canvas.toBlob('image/jpeg', quality=0.5)
              â””â”€â–º FileReader.readAsDataURL
                    â””â”€â–º base64 = result.split(',')[1]
                          â””â”€â–º s.sendRealtimeInput({ media: { data: base64, mimeType: 'image/jpeg' } })
```

Frames are sent at **320Ã—240 @ JPEG q=0.5** to keep bandwidth low while giving the model enough visual context.

---

## 4. Subsystem B â€” Multi-agent Story Engine (Backend)

### 4.1 Agent Roles

| Agent | Model | Key tools / output | ADK type |
|---|---|---|---|
| **Adventure Seeker** (Researcher) | `gemini-2.5-flash` | `google_search` + `BuiltInPlanner` | `Agent` |
| **Guardian of Balance** (Judge) | `gemini-2.5-flash` | Structured `JudgeFeedback` (`{ status, feedback }`) | `Agent` with `output_schema` |
| **Storysmith** (Content Builder) | `gemini-2.5-pro` | Markdown Interactive Story | `Agent` |
| **Orchestrator** | â€” | Coordinates the pipeline | `SequentialAgent` + `LoopAgent` |

### 4.2 Orchestration Logic

```
story_engine_pipeline (SequentialAgent)
  â””â”€â–º research_loop (LoopAgent, max_iterations=3)
  â”‚     â”œâ”€â–º adventure_seeker  â†’ saves output to state["research_findings"]
  â”‚     â”œâ”€â–º guardian_of_balance â†’ saves JudgeFeedback to state["judge_feedback"]
  â”‚     â””â”€â–º escalation_checker (BaseAgent)
  â”‚           â”œâ”€â–º feedback.status == "pass"  â†’ EventActions(escalate=True)  â† exits loop
  â”‚           â””â”€â–º feedback.status == "fail"  â†’ loop again (up to 3 times)
  â”‚
  â””â”€â–º storysmith              â†’ reads state["research_findings"], outputs markdown story
```

**EscalationChecker** is a custom `BaseAgent` subclass. It reads `session.state["judge_feedback"]` and yields an `Event(escalate=True)` to break the `LoopAgent`, or an empty event to continue.

### 4.3 A2A Communication

Each of the three leaf agents (Researcher, Judge, Content Builder) runs as a standalone **A2A server** (served by `adk_app.py`). The Orchestrator connects to them via `RemoteA2aAgent`, which:

1. Reads the agent card from `<agent_url>/.well-known/agent-card.json`
2. Posts tasks over HTTP using the A2A protocol
3. Uses an **authenticated HTTPX client** (`authenticated_httpx.py`) to attach Google OAuth2 bearer tokens automatically â€” required when deployed on Cloud Run

```
Orchestrator
  â”œâ”€â”€ RemoteA2aAgent("researcher")  â†’ HTTP POST  http://localhost:8001/a2a/... (Adventure Seeker)
  â”œâ”€â”€ RemoteA2aAgent("judge")       â†’ HTTP POST  http://localhost:8002/a2a/... (Guardian of Balance)
  â””â”€â”€ RemoteA2aAgent("content_builder") â†’ HTTP POST  http://localhost:8003/a2a/... (Storysmith)
```

### 4.4 FastAPI Proxy Layer

`app/main.py` sits between the browser and the Orchestrator:

```
Browser POST /api/chat_stream
  â””â”€â–º FastAPI
        â”œâ”€â–º list_agents()         (if agent_name not yet known)
        â”œâ”€â–º get_session()         (reuse existing session if session_id provided)
        â”‚    â””â”€â–º create_session() (otherwise create a new one)
        â””â”€â–º query_adk_server()    (SSE stream from orchestrator /run_sse)
              â””â”€â–º event_generator()
                    â”œâ”€â–º "researcher" event  â†’ yield progress: "ğŸ” Adventure Seeker is gathering..."
                    â”œâ”€â–º "judge" event       â†’ yield progress: "âš–ï¸ Guardian of Balance is evaluating..."
                    â”œâ”€â–º "content_builder"   â†’ yield progress: "âœï¸ Storysmith is writing..."
                    â””â”€â–º final content       â†’ yield result: <markdown story>

Response: application/x-ndjson (newline-delimited JSON)
```

All communication with the ADK server is done via `httpx_sse.aconnect_sse` for real-time streaming.

---

## 5. Data Flows

### 5.1 Live Storytelling End-to-End

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Child's Browser                                            â”‚
â”‚                                                             â”‚
â”‚  Mic â”€â”€â–º PCM 16kHz â”€â”€â–º sendRealtimeInput â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â–º Gemini Live API
â”‚                                                             â”‚    (gemini-2.5-flash-
â”‚  Camera â”€â”€â–º JPEG 320Ã—240 / 4s â”€â”€â–º sendRealtimeInput â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â–º  native-audio-preview)
â”‚                                                             â”‚         â”‚
â”‚  AI Audio (PCM 24kHz) â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ modelTurn.inlineData â—„â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  AI Text Transcript  â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ outputTranscription â—„â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                             â”‚         â”‚
â”‚  toolCall: generateIllustration â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚    â””â”€â–º Gemini Image API (gemini-2.5-flash-image)            â”‚         â”‚
â”‚          â””â”€â–º inlineData.data (PNG) â†’ <img>                  â”‚         â”‚
â”‚                                                             â”‚         â”‚
â”‚  toolCall: awardBadge â†’ achievement popup                   â”‚         â”‚
â”‚  toolCall: showChoice â†’ overlay buttons â†’ sendClientContent â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 5.2 Multi-agent Story Engine End-to-End {#52-multi-agent-story-engine-end-to-end}

```
User types topic
  â”‚
  â–¼
Browser POST /api/chat_stream  { message, user_id, session_id? }
  â”‚
  â–¼
FastAPI (port 8000)
  â”œâ”€â–º creates / reuses ADK session
  â””â”€â–º SSE stream from Orchestrator (port 8004)
        â”‚
        â”œâ”€â”€ LoopAgent starts:
        â”‚   â”œâ”€â–º Adventure Seeker (8001) â€” google_search â†’ research_findings (state)
        â”‚   â”œâ”€â–º Guardian of Balance (8002) â€” evaluate research â†’ judge_feedback (state)
        â”‚   â””â”€â–º EscalationChecker
        â”‚         â”œâ”€â”€ FAIL â†’ loop (max 3Ã—)
        â”‚         â””â”€â”€ PASS â†’ escalate, exit loop
        â”‚
        â””â”€â”€ Storysmith (8003) â€” reads research_findings â†’ markdown story
              â”‚
              â–¼
        FastAPI streams NDJSON to browser:
          { type: "progress", text: "ğŸ” Adventure Seeker is gathering..." }
          { type: "progress", text: "âš–ï¸ Guardian of Balance is evaluating..." }
          { type: "progress", text: "âœï¸ Storysmith is writing..." }
          { type: "result",   text: "# Story Title\n## Chapter..." }
```

---

## 6. Service Topology & Ports

| Service | Port | Technology | Start command |
|---|---|---|---|
| **App** (Frontend + API proxy) | `8000` | FastAPI + Uvicorn | `uvicorn main:app` |
| **Adventure Seeker** (Researcher) | `8001` | ADK A2A server | `adk_app.py --a2a` |
| **Guardian of Balance** (Judge) | `8002` | ADK A2A server | `adk_app.py --a2a` |
| **Storysmith** (Builder) | `8003` | ADK A2A server | `adk_app.py --a2a` |
| **Orchestrator Agent** | `8004` | ADK server (non-A2A) | `adk_app.py` |

All services are started in the correct order by `run_local.sh`. A 5-second sleep ensures leaf agents are ready before the orchestrator tries to resolve their agent cards.

---

## 7. Deployment

All five services are containerised with individual `Dockerfile`s and deployed to **Google Cloud Run** via `deploy.sh`.

**Deployment order** (enforced by the script):

1. Adventure Seeker â†’ deployed, URL captured
2. Guardian of Balance â†’ deployed, URL captured
3. Storysmith â†’ deployed, URL captured
4. Orchestrator â†’ deployed (receives agent URLs as env vars), URL captured
5. App â†’ deployed (receives orchestrator URL as `AGENT_SERVER_URL`)

The `course-creator` (App) Cloud Run service is publicly accessible. The four agent services have `--no-allow-unauthenticated` and require a Google OAuth2 bearer token â€” handled transparently by `authenticated_httpx.py` using Application Default Credentials.

**Observability:** The FastAPI app instruments traces with **OpenTelemetry** and exports them to **Google Cloud Trace** via `CloudTraceSpanExporter`.

---

## 8. Key Design Decisions

### Direct API from browser (Live Storytelling)
The frontend calls the Gemini Live API directly using the `VITE_API_KEY` without routing through a backend. This minimises latency for the real-time audio loop, but means the API key is exposed in the browser environment â€” acceptable for a hackathon demo, should be proxied in production.

### Single-component frontend
All state and logic live in `App.tsx`. This was chosen for simplicity and speed of iteration during a hackathon. Future refactoring would split audio, camera, session management, and UI into separate hooks/components.

### LoopAgent with EscalationChecker
Rather than using a fixed number of research passes, the Judge's `output_schema` produces a structured `{ status: "pass"|"fail" }` verdict. The `EscalationChecker` reads this from session state and escalates the loop early when quality is sufficient (up to a safety cap of 3 iterations).

### A2A over direct agent calls
Using the A2A protocol means each agent is independently deployable and scalable. The Orchestrator only needs to know the agent card URL â€” not the implementation. This also enables mixing agents written in different languages or frameworks in the future.

### Session state as the shared-memory bus
The Orchestrator saves agent outputs (`research_findings`, `judge_feedback`) into ADK **session state**. Sub-agents read from this state in their prompts via the `{state[key]}` template syntax. This avoids passing large payloads through function arguments and keeps the inter-agent contract simple.

### Authenticated HTTPX client
`authenticated_httpx.py` wraps `google.auth.transport.requests` to inject an OAuth2 bearer token into every outgoing request. The same helper is used both by the Orchestrator (to call leaf agents) and by the FastAPI app (to call the Orchestrator). In local development, tokens are sourced from `gcloud auth application-default login`.

---

## 9. Tech Stack Summary

| Layer | Technology | Version |
|---|---|---|
| Live AI | Gemini 2.5 Flash Native Audio | `gemini-2.5-flash-native-audio-preview-12-2025` |
| Image AI | Gemini 2.5 Flash Image | `gemini-2.5-flash-image` |
| Adventure Seeker / Researcher | Gemini 2.5 Flash | `gemini-2.5-flash` |
| Guardian of Balance / Judge | Gemini 2.5 Flash | `gemini-2.5-flash` |
| Storysmith / Story Builder | Gemini 2.5 Pro | `gemini-2.5-pro` |
| Multi-agent framework | Google Agent Development Kit (ADK) | `1.22.0` |
| Agent protocol | A2A (Agent-to-Agent) | `a2a-sdk 0.3.*` |
| Frontend | React 19 + TypeScript | â€” |
| Build tool | Vite 6 | â€” |
| Styling | TailwindCSS | â€” |
| Backend | FastAPI + Uvicorn | `0.123.*` / `0.40.0` |
| Python | CPython | `â‰¥ 3.10, < 3.14` |
| Package manager | uv | â€” |
| Observability | OpenTelemetry + Google Cloud Trace | `1.11.0` |
| Hosting | Google Cloud Run | â€” |
